<!DOCTYPE html>
<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="icon" href="http://vcipl-okstate.org/pbvs/20/images/logo_o_png.ico"><title>Welcome to PBVS '22</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./css/bootstrap.min.css">
    <script src="./css/jquery.min.js.descarga"></script>
    <script src="./css/bootstrap.min.js.descarga"></script>
	<script src="./js/scrolling-nav.js"></script>
    <link href="./css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="./css/style.css" rel="stylesheet" type="text/css">
	<link href="./css/scrolling-nav.css" rel="stylesheet">
<style>
    #content li {
       margin-left:-20px;  
    }   
</style>
</head>

<body>

<div class="navbar navbar-default navbar-fixed-top" id="navi_bar">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-ex-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="#"><span><strong>IEEE PBVS '22</strong></span></a>
        </div>
        <div class="collapse navbar-collapse" id="navbar-ex-collapse">
            <ul class="nav navbar-nav navbar-right">
                <li ><a href="index.html"><strong>Home</strong></a></li>
                <li><a href="call_for_paper.html"><strong>Call for Paper</strong></a></li>
                <li  class="active"><a href="challenge.html"><strong>Challenges</strong></a></li>
                <li><a href="submission.html"><strong>Submission</strong></a></li>
                <li><a href="organization.html"><strong>Organization</strong></a></li>
                <li><a href="program.html"><strong>Program</strong></a></li>
                <li><a href="keynotes.html"><strong>Keynotes</strong></a></li>
                <li><a href="datasets.html"><strong>Datasets</strong></a></li>
                <li><a href="awards.html"><strong>Awards</strong></a></li>
                <li><a href="history.html"><strong>History</strong></a></li>
            </ul>
        </div>
    </div>
</div>


<div class="section" id="announcement">
    <div class="container">
        <div class="row">
<p align="center"><strong>Announcement:  this year, <u>THREE</u> challenges
	are being organized in the framework of PBVS'2022 workshop. (Details to be updated in next few weeks) </strong>
</p>
</div>
</div>
</div>

<!--
<div class="section" id="announcement">
    <div class="container">
        <div class="row">
            <div class="panel panel-primary">
                <div class="panel-heading">
                    <h3 class="panel-title text-center">Challenges Organized in Conjunction with PBVS 2022</h3>
                </div>
                <div class="panel-body">
                    <div class="row">
                        <div class="col-md-12">
                            <p align="justify"><strong>ANNOUNCEMENT: </strong> This year, <strong>THREE</strong>  different challenges
								are being organized in the framework of PBVS'2022 workshop; details on these challenges are given below. 
							</p>
							<p align="justify">	(In next weeks, links for online evaluations will be provided.)
							</p>
                        </div>
                   </div>    
            </div>
            </div>
        </div>
    </div>
</div>
-->


<div class="section" id="challenge_1">
    <div class="container">
        <div class="row">
            <div class="panel panel-primary">
                <div class="panel-heading">
                    <h3 class="panel-title text-center">3rd Thermal Image Super-Resolution Challenge (TISR)</h3>
                </div>
                <div class="panel-body">
                    <div class="row">
                        <div class="col-md-12">
                            <p align="justify">The third thermal image super-resolution (TISR) challenge consists in obtaining super-resolution images at x2 and x4 scales from the given thermal images.</p>
							<p align="justify">The third edition of this challenge will follow the same setup as the second edition (i.e., just the mid- and high-resolution images from the dataset used in the first edition are considered). Ground truth images for the x4 scale correspond to the provided high- resolution images; in other words, each team should down-sample the given images by x4 and use these down-sampled images (by adding noise) as inputs to develop their solutions. Regarding the x2 super-resolution solution, it should be developed using as an input the given mid-resolution images acquired with the camera Axis Q2901-E and as an output, the corresponding high-resolution images, of the same scene, but acquired with the FLIR FC-632O camera. Strictly speaking, the x2 scale proposed solution should tackle both problems, i.e., generating the super-resolution of the images acquired with the Axis Q2901-E camera and mapping images from one domain (Axis Q2901-E camera) to another domain (FLIR FC-632O camera).</p>
							<P align="justify">More details and dataset in CodaLab page:: <a href="https://codalab.lisn.upsaclay.fr/competitions/1322" class=content target="_blank"><strong>LINK</strong></a></P>
						</div>
                   </div>    
            </div>
            </div>
        </div>
    </div>
</div>

<div class="section" id="challenge_2">
    <div class="container">
        <div class="row">
            <div class="panel panel-primary">
                <div class="panel-heading">
                    <h3 class="panel-title text-center">Multi-modal Aerial View Object Classification Challenge (MAVOC)</h3>
                </div>
                <div class="panel-body">
                    <div class="row">
                        <div class="col-md-12">
                            <p align="justify">Electro-optical (EO) sensors that capture images in the visible spectrum such as RGB and grayscale images, have been most prevalent in the computer vision research area. However, other sensors such as synthetic aperture radar (SAR) can reproduce images from radar signals that in some cases could complement EO sensors when such sensors fail to capture significant information (i.e. weather condition, no visible light, etc)</p>
							<p align="justify">An ideal automated target recognition system would be based on multi-sensor information to compensate for the shortcomings of either of the sensor-based platforms individually. However, it is currently unclear if/how using EO and SAR data together can improve the performance of automatic target recognition (ATR) systems. Thus, the motivation for this challenge is to understand if and how data from one modality can improve the learning process for the other modality and vice versa. Ideas from domain adaptation, transfer learning or fusion are welcomed to solve this problem.</p>
							<p align="justify">Jointly with PBVS workshop we have a PBVS challenge on Multi-modal Aerial view Imagery Classification, that is, the task of predicting the class label of an aerial low resolution image based on a set of prior examples of images and their class labels. Two tracks of data are made available: EO + SAR, and SAR.</p>
							<P align="justify">Dataset is hosted on CodaLabs but will be updated with cleaner data.</P>
							<P align="justify">More details and dataset in CodaLab page:</P> 
							<P><a href="https://codalab.lisn.upsaclay.fr/competitions/1388" class=content target="_blank"><strong>TRACK 1</strong></a></P>
							<P><a href="https://codalab.lisn.upsaclay.fr/competitions/1392" class=content target="_blank"><strong>TRACK 2</strong></a></P>
						</div>
                   </div>    
            </div>
            </div>
        </div>
    </div>
</div>

<div class="section" id="challenge_3">
    <div class="container">
        <div class="row">
            <div class="panel panel-primary">
                <div class="panel-heading">
                    <h3 class="panel-title text-center">Semi-Supervised Hyperspectral Object Detection Challenge (SSHODC)</h3>
                </div>
                <div class="panel-body">
                    <div class="row">
                        <div class="col-md-12">
                            <p align="justify">Semi-supervised learning has developed into a highly researched problem as it minimizes the labeling costs while still achieving performance levels comparable to a fully labeled dataset. However, most semi-supervised learning algorithms are based on pre-trained models on ImageNet and are thus challenging to port to other image domains, especially those with more than three bands. In this competition, we present the application of a newly acquired dataset collected from a university rooftop with a hyperspectral camera to perform object detection. We present a semi-supervised learning challenge with 10% labeled data with three moving object categories: vehicles, bus and bike. Additional details, with links to dataset and CodaLab server are provided <a href="https://sites.google.com/g.rit.edu/sshodc-pbvs-2022" class=content target="_blank"><strong>HERE</strong></a></P>
						</div>
                   </div>    
            </div>
            </div>
        </div>
    </div>
</div>

<!--
<div class="container">
	<div class="row">
	<div>
		<div>
			<div style="background-color:#ffffff">
				<br><br>
				<h3 style="font-family:Neuropol"><font color="#000000"><p align="center"><br><br>2nd. Thermal Image Super-Resolution Challenge</p></font></h3>
			</div>
		</div>
	</div>
</div>

<div class="section" id="challenge">
    <div class="container">
        <div class="row">
            <div class="panel panel-primary" id="overview">
                <div class="panel-heading">
                    <h3 class="panel-title text-center">Objective & Scope</h3>
                </div>
                <div class="panel-body">
                    <p align="justify">The thermal image super-resolution (TISR) problem has become an attractive research topic in recent years, mainly due to the appealing results obtained with recent deep learning-based approaches. In order to define a common benchmark for evaluating the different contributions, the first challenge on TISR has been proposed at the PBVS-2020 workshop. Due to the success of that first challenge, and trying to keep improving the obtained results, this year the second challenge on TISR is proposed in the framework of the PBVS-2021 workshop.</p>
					<p align="justify">
					<b>The challenge stated for this year consists in obtaining super-resolution images at x2 and x4 scales from the given images.</b>
					</p>
					<p align="justify">
					Just the mid- and high-resolution images from last year dataset will be considered. Ground truth images for the x4 scale corresponds to the provided high-resolution images; in other words, each team should down-sample the given images by x4 and use these down-sampled images (by adding noise) as inputs to develop their solutions. Regarding the x2 super-resolution solution, it should be developed using as an input the given mid-resolution images acquired with the camera Axis Q2901-E and as an output, the corresponding high-resolution images, of the same scene, but acquired with the FLIR FC-632O camera. In other words, the x2 scale proposed solution should be able to tackle both problems, i.e., generating the super-resolution of the images acquired with the camera Axis Q2901-E camera; as well as mapping images from one domain (Axis Q2901-E camera) to another domain (FLIR FC-632O camera).
					</p>
                </div>
            </div>

			<div class="panel panel-primary" id="winner">
                <div class="panel-heading">
                    <h3 class="panel-title text-center">Winning Teams</h3>
                </div>
                <div class="panel-body">
					<div class="row">
						<div class="col-md-6" >
							<p align="center"><strong>Evaluation 1 (x4): SVNIT_NTNU team</strong></p>
							<p align="center">Heena Patel*, Vishal Chudasama*, Kalpesh Prajapati*, Anjali Sarvaiya*,
								Kishor P. Upla*, Raghavendra Ramachandra+, Kiran Raja+ and Christoph Busch+</p>
							<p align="center">*:SVNIT, Surat, India, +:NTNU, Gjøvik, Norway</p> 
							<img src="images/challenge_winner_1.jpg" class="center-block img-responsive" id="winner1">
						</div>
						
						<div class="col-md-6" >
							<p align="center"><strong>Evaluation 2 (MR2HR): ULB-LISA team</strong></p>
							<p align="center">Feras Almasri, Thomas Vandamme, and Olivier Debeir</p>
							<p align="center">Universite Libre de Bruxelles, Belgium</p> 
							<img src="images/challenge_winner_2.JPG" class="center-block img-responsive" id="winner2">
						</div>
						
					</div>
				</div>
            </div>

			
            
			<div class="panel panel-primary" id="dataset">
				<div class="panel-heading">
					<h3 class="panel-title text-center">Dataset</h3>
				</div>
				 <div class="panel-body">
                    <p align="justify">The dataset used for this second TISR challenge consists of the mid- and high-resolution images of last year's challenge. These images have been acquired at the same time with different cameras. Technical details are provided below in <a class="js-scroll-trigger" href="#table1">Table 1</a>, some illustrations from each camera are depicted in <a class="js-scroll-trigger" href="#fig1">Fig. 1</a>.</p>
					<center>
					<table class="table table-bordered" id="table1" style="width:60%">
						<tbody>
							<tr><th>Image Description&nbsp;&nbsp;&nbsp;</th><th>Brand Camera&nbsp;&nbsp;</th><th>FOV&nbsp;&nbsp;&nbsp;&nbsp;</th><th>Native Resolution&nbsp;&nbsp;</th></tr>
							<tr style="color:lightgray"><td>Low (LR)<sup>+</sup></td><td>Axis Domo P1290</td><td style="text-align:right">8mm</td><td style="text-align:right">160x120</td></tr>
							<tr><td>Mid (MR)</td><td>Axis Q2901-E</td><td style="text-align:right">9mm</td><td style="text-align:right">320x240</td></tr>
							<tr><td>High (HR)</td><td>FC-632O FLIR</td><td style="text-align:right">13mm</td><td style="text-align:right">640x512*</td></tr>
						</tbody>
					</table>
					<i>Table 1 - Thermal Camera Specification (* Cropped to 640x480) (+ images not used in this second challenge).</i>
					</center>
					<br/>
					<center>
					<img src="challenge/img/dataset.png" width="70%" id="fig1" /><br/>
					<i>Figure 1 - Examples from each camera (+ images not used in this second challenge).</i>
					</center><br/>
					
					<p align="justify">
					The original dataset contains a total of 1021 thermal images, which were simultaneously taken with each camera. All images are semi-paired. From all these images, 1001 are provided to the participants (951 for training and 50 for testing), while the remaining 20 are used for evaluating the results from the different teams (remember that from the given dataset just mid- and high-resolution images are needed, low-resolution images are also included since they are a part of the original dataset).</p>
					
					<p align="right">&nbsp;</p>
                </div>
			</div>
			
			<div class="panel panel-primary" id="evaluation">
				<div class="panel-heading">
					<h3 class="panel-title text-center">Evaluation</h3>
				</div>
				 <div class="panel-body">
                    <p align="justify">PSNR and structural similarity (SSIM) measures are going to be computed over a small set of images left for evaluating the performance of the proposed solution. Two kinds of evaluations are going to be performed. For the first evaluation, a set of 10 single down-sampled and noisy images will be shared for traditional evaluation as shown in <a class="js-scroll-trigger" href="#evaluation01">Fig. 2</a>. For the second evaluation a set of 10 real images, from the MR dataset, will be shared. In this case, the obtained SR images will be compared with the corresponding real High-Resolution semi-paired images, as shown in <a class="js-scroll-trigger" href="#evaluation02">Fig. 3</a>. For the second evaluation, HR images are going to be registered with the computed SR images in order to compute PSRN & SSIM metrics.</p>
					
					<center>
						<img src="challenge/img/Challenge01.png" width="40%" id="evaluation01" /><br/>
						<i>Figure 2 - First evaluation diagram (x4 for high).</i>
						<br/><br/>
						
						<img src="challenge/img/Challenge02.png" width="40%" id="evaluation02" /><br/>
						<i>Figure 3 - Second evaluation diagram* (x2 for MR2HR).</i>
						<br/><br/>
					</center>
					
					<p align="right">&nbsp;</p>
					<p>*Due to the semi-paired nature, for a fair comparison, the evaluation will be performed over a small region (50% of image size) centered in the image.</p>
					
					<p align="right">&nbsp;</p>
					
					<p align="justify">
						<ul>
							<li>Evaluation 1: 10 noisy down-sampled images, from HR camera, will be provided to compute the corresponding SR. Bicubic function should be used for down-sampling at scale of 4 and Gaussian noise** with mean=0 and sigma=10 should be considered. Results will be evaluated as follows: <br/><center><img src="challenge/img/formula01.PNG" width="20%" /></center>where EVAL is PSNR & SSIM measures and N is the number of validation images.<br/><br/>** On python for Gaussian noise, use np.random.normal(mean, sigma, img.shape)</li><br/>
							
							<li>Evaluation 2: MR images as provided by the camera will be shared; this evaluation will be performed just for the x2 scale. The average evaluation value will be computed as follows:<br/><center><img src="challenge/img/formula02.PNG" width="20%" /></center>where EVAL is PSNR and SSIM measures, and N is the number of validation images (note that EVAL will be applied just on a part of the image to avoid regions without overlap due to the bias of the cameras).</li><br/>
						<!--- 
						R_{\times 4}=\frac{1}{N}\sum_{1}^{N}\textit{EVAL}\left ( GT_{N},SR_{N}^{\times 4} \right )
---
R_{\times 2}=\frac{1}{N}\sum_{1}^{N}\overline{\textit{EVAL}}\left ( GT_{N},SR_{N}^{\times 2} \right )

						-->
<!--						</ul>
					</p>
					<p align="right">&nbsp;</p>
					<p align="justify">
						<center>
						<table class="table table-bordered" id="table2" style="width:60%">
							<tbody>
								<tr><th>Scale&nbsp;&nbsp;&nbsp;</th><th>Evaluation1 (SISR x4)&nbsp;&nbsp;</th><th>Evaluation2 (SISR MR2HR)</th></tr>
								<tr><td>x2</td><td style="text-align:center">---</td><td style="text-align:center">PSRN/SSIM</td></tr>
								<tr><td>x4</td><td style="text-align:center">PSRN/SSIM</td><td style="text-align:center">---</td></tr>
							</tbody>
						</table>
						<i>Table 2 - Evaluations measures.</i>
						<center>
					</p>
					<p align="right">&nbsp;</p>
					<p align="justify">
						<b>Note:</b> The super-resolution (SR) results must be submitted in a <b><a href="challenge/structure.zip">zip file</a></b> together with a short description of the proposed approach to <<a href="mailto:pbvs21.tisr.challenge@gmail.com">pbvs21.tisr.challenge@gmail.com</a>>. The approach with the highest performance in most evaluation metrics will be the winner of the challenge.
					</p>
					
                </div>
			</div>
			
			<div class="panel panel-primary" id="dates">
				<div class="panel-heading">
					<h3 class="panel-title text-center">Benchmark</h3>
				</div>
				 <div class="panel-body">
                    <p align="justify">
						Feel free to check the 1st. Thermal Image Super-Resolution Challenge <a href="http://vcipl-okstate.org/pbvs/20/challenge.html" target="_BLANK">here</a> for more information.<br/><br/>
						For benchmark, please check <i>Rivadeneira et al. (2020). Thermal Image Super-Resolution Challenge – PBVS 2020. In The 16th IEEE Workshop on Perception Beyond the Visible Spectrum on the Conference on Computer Vision and Pattern Recongnition (CVPR 2020) (Vol. 2020-June, pp. 432–439)</i> <a href="https://openaccess.thecvf.com/content_CVPRW_2020/html/w6/Rivadeneira_Thermal_Image_Super-Resolution_Challenge_-_PBVS_2020_CVPRW_2020_paper.html" target="_BLANK">paper HERE</a>.
					</ul>
					</p>
                </div>
			</div>
			
			<!--div class="panel panel-primary" id="awards">
				<div class="panel-heading">
					<h3 class="panel-title text-center">Awards</h3>
				</div>
				 <div class="panel-body">
						<div class="col-md-12">
							<p align="center"><strong>Comming soon</strong></p>
						</div>
                </div>
			</div-->
<!--			
			<div class="panel panel-primary" id="dates">
				<div class="panel-heading">
					<h3 class="panel-title text-center">Important Dates</h3>
				</div>
				 <div class="panel-body">
                    <p align="justify">
						<ul>
						<li>Registration open & dataset released: January 18, 2021</li>
						<li>Evaluation images distributed: March 2, 2021</li>
						<li>Deadline for challenge & result submitted: <b>March 12, 2021</b></li>
						<li>Winner announcement: June 19, 2021</li>
					</ul>
					</p>
                </div>
			</div>
			
			<div class="panel panel-primary" id="">
				<div class="panel-heading">
					<h3 class="panel-title text-center">Register</h3>
				</div>
				 <div class="panel-body">
                    <p align="justify"><iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeOQB9SXZL2dleHIf9dLBQbY7Q5G4oVAOWODKKBrvmcmBZoQg/viewform?embedded=true" width="100%" height="500" frameborder="0" marginheight="0" marginwidth="0">Cargando…</iframe></p>
					 <p align="right">&nbsp;</p>
                </div>
			</div>
			
			<div class="panel panel-primary" id="">
				<div class="panel-heading">
					<h3 class="panel-title text-center">Contact Us</h3>
				</div>
				<div class="panel-body">
					<div class="row">
						<div class="col-md-12">
							<p align="center"><strong>Rafael Rivadeneira</strong></p>
							<p align="center">Guayaquil, Ecuador</p>
							<p align="center"><a href="mailto:rrivaden@espol.edu.ec" class="content">rrivaden@espol.edu.ec</a></p>
						</div>
					</div>
				</div>

			</div>
			
            
        </div>
    </div>
</div>
-->
</body></html>